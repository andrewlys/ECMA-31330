@InProceedings{ada-boost,
author="Freund, Yoav
and Schapire, Robert E.",
editor="Vit{\'a}nyi, Paul",
title="A desicion-theoretic generalization of on-line learning and an application to boosting",
booktitle="Computational Learning Theory",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="23--37",
abstract="We consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update rule of Littlestone and Warmuth [10] can be adapted to this mode yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games and prediction of points in ℝn. We also show how the weight-update rule can be used to derive a new boosting algorithm which does not require prior knowledge about the performance of the weak learning algorithm.",
isbn="978-3-540-49195-8"
}

@article{alexnet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet classification with deep convolutional neural networks},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {60},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3065386},
doi = {10.1145/3065386},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
journal = {Commun. ACM},
month = may,
pages = {84–90},
numpages = {7}
}
@misc{euclidean,
      title={Improving Factor-Based Quantitative Investing by Forecasting Company Fundamentals}, 
      author={John Alberg and Zachary C. Lipton},
      year={2018},
      eprint={1711.04837},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1711.04837}, 
}
@misc{tft,
      title={Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting}, 
      author={Bryan Lim and Sercan O. Arik and Nicolas Loeff and Tomas Pfister},
      year={2020},
      eprint={1912.09363},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1912.09363}, 
}
@misc{seasonalization,
      title={Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series: A Clustering Approach}, 
      author={Kasun Bandara and Christoph Bergmeir and Slawek Smyl},
      year={2018},
      eprint={1710.03222},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.03222}, 
}
@article{meanscale,
   title={Recurrent Neural Networks for Time Series Forecasting: Current status and future directions},
   volume={37},
   ISSN={0169-2070},
   url={http://dx.doi.org/10.1016/j.ijforecast.2020.06.008},
   DOI={10.1016/j.ijforecast.2020.06.008},
   number={1},
   journal={International Journal of Forecasting},
   publisher={Elsevier BV},
   author={Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
   year={2021},
   month=jan, pages={388–427} }
@misc{NaNPolicy,
      title={Modeling Missing Data in Clinical Time Series with RNNs}, 
      author={Zachary C. Lipton and David C. Kale and Randall Wetzel},
      year={2016},
      eprint={1606.04130},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.04130}, 
}
@misc{dataAug,
      title={Improving the Accuracy of Global Forecasting Models using Time Series Data Augmentation}, 
      author={Kasun Bandara and Hansika Hewamalage and Yuan-Hao Liu and Yanfei Kang and Christoph Bergmeir},
      year={2020},
      eprint={2008.02663},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2008.02663}, 
}
@article{sentimentAnalysis,
author = {Du, Kelvin and Xing, Frank and Mao, Rui and Cambria, Erik},
title = {Financial Sentiment Analysis: Techniques and Applications},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3649451},
doi = {10.1145/3649451},
abstract = {Financial Sentiment Analysis (FSA) is an important domain application of sentiment analysis that has gained increasing attention in the past decade. FSA research falls into two main streams. The first stream focuses on defining tasks and developing techniques for FSA, and its main objective is to improve the performances of various FSA tasks by advancing methods and using/curating human-annotated datasets. The second stream of research focuses on using financial sentiment, implicitly or explicitly, for downstream applications on financial markets, which has received more research efforts. The main objective is to discover appropriate market applications for existing techniques. More specifically, the application of FSA mainly includes hypothesis testing and predictive modeling in financial markets. This survey conducts a comprehensive review of FSA research in both the technique and application areas and proposes several frameworks to help understand the two areas’ interactive relationship. This article defines a clearer scope for FSA studies and conceptualizes the FSA-investor sentiment-market sentiment relationship. Major findings, challenges, and future research directions for both FSA techniques and applications have also been summarized and discussed.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {220},
numpages = {42},
keywords = {Financial sentiment analysis, financial forecasting, natural language processing, information system, machine learning, deep learning}
}