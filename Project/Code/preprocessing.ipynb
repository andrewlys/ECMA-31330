{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewlys/ECMA-31330/blob/main/Project/Code/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve_8dZ_uuKvM",
        "outputId": "bdaf1606-96f6-4916-ac6d-57b21c7ad641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.13.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFqz0B0VHxGV",
        "outputId": "78021bc7-3034-44cc-988f-66d614e8c475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzzZTUPfUD1f"
      },
      "source": [
        "We filter for companies that have been public for at least 60 months."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxSzUKKdWgHF"
      },
      "source": [
        "We begin our pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB7GU6oZbsRo"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ECMA 31330 Project/ecma_33130_raw.csv')\n",
        "raw_data.datadate = pd.to_datetime(raw_data.datadate)\n",
        "raw_data.ipodate = pd.to_datetime(raw_data.ipodate)\n",
        "last_date = raw_data.groupby('gvkey').last()['datadate']\n",
        "first_date = raw_data.groupby('gvkey').first()['ipodate']\n",
        "first_date.where(pd.notnull,\n",
        "                 raw_data.groupby('gvkey').first()['datadate'],\n",
        "                 inplace=True)\n",
        "comp_to_keep = first_date + pd.DateOffset(months = 60) < last_date\n",
        "df = raw_data[raw_data['gvkey'].isin(comp_to_keep[comp_to_keep].index)]\n",
        "df = df.reset_index(drop=True)\n",
        "# Momentum Features\n",
        "df = df.sort_values(['gvkey', 'datadate'])\n",
        "# trailing returns\n",
        "for n in [3, 9, 12, 18]:\n",
        "    df[f'ret_{n}m'] = df.groupby('gvkey')['prccq'].pct_change(n, fill_method=None)\n",
        "    df[f'rel:ret_{n}m'] = df.groupby('gvkey')[f'ret_{n}m'].rank(pct=True)\n",
        "# book to market =  shareholder equity / (price close * common shares outstanding)\n",
        "df['bkmktq'] = df['seqq'] / (df['prccq'] * df['cshoq'])\n",
        "df['rel:bkmktq'] = df.groupby('datadate')['bkmktq'].rank(pct=True)\n",
        "# Enterprise Value\n",
        "df['evq'] = (\n",
        "    df['prccq'] * df['cshoq']  # Market capitalization\n",
        "    + df['dlttq']              # Long-term debt\n",
        "    + df['dlcq']               # Debt in current liabilities\n",
        "    - df['cheq']               # Cash and short-term investments\n",
        ")\n",
        "# Earnings yield\n",
        "df['eyq'] = df['oiadpq'] / df['evq']\n",
        "df['rel:eyq'] = df.groupby('datadate')['eyq'].rank(pct=True)\n",
        "# NaN Policy\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "nan_cols = [\n",
        "    f'is_nan:{col}' for col in df.columns\n",
        "    if col not in ['gvkey', 'datadate']\n",
        "]\n",
        "cols_to_nan = [col for col in df.columns if col not in ['gvkey', 'datadate']]\n",
        "nan_df = df[cols_to_nan].isna().astype(int)\n",
        "nan_df.columns = nan_cols\n",
        "df = pd.concat([df, nan_df], axis=1)\n",
        "df[cols_to_nan] = df.groupby(['gvkey', 'datadate'])[cols_to_nan].ffill()\n",
        "df[cols_to_nan] = df[cols_to_nan].fillna(0)\n",
        "# transform\n",
        "numrcl_cols = [\n",
        "    col for col in df.columns\n",
        "    if col not in ['gvkey', 'datadate', 'fyearq', 'fqtr', 'exchg', 'ipodate']\n",
        "    and col[:3] != 'rel'\n",
        "    and col[:6] != 'is_nan'\n",
        "    and pd.api.types.is_numeric_dtype(df[col])\n",
        "]\n",
        "min_val = df[numrcl_cols].min(axis=None)\n",
        "df[numrcl_cols] += np.abs(min_val)\n",
        "import numba\n",
        "norm_factor = (\n",
        "    df.groupby(['gvkey', 'datadate'])[numrcl_cols]\n",
        "      .expanding(min_periods= 1, method = 'table')\n",
        "      .mean(numeric_only = True, engine = 'numba', engine_kwargs={'parallel':True})\n",
        "      .reset_index(drop = True)\n",
        ")\n",
        "df[numrcl_cols] /= norm_factor[numrcl_cols]\n",
        "df[numrcl_cols] = np.log1p(df[numrcl_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKDVu9ellZsf"
      },
      "outputs": [],
      "source": [
        "# deseasonalization and detrend\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "cols_to_deszn = [\n",
        "    col for col in df.columns\n",
        "    if (\n",
        "        col not in ['gvkey', 'datadate', 'fyearq', 'fqtr', 'exchg', 'ipodate']\n",
        "        and col[:6] != 'is_nan'\n",
        "        and df[col].dtype in [np.float64, np.int64]\n",
        "        and df[col].nunique() > 4\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBES2oI4nnw9"
      },
      "outputs": [],
      "source": [
        "def deszn(df, cols_to_deszn):\n",
        "  szn_cols = {col:f'szn:{col}' for col in cols_to_deszn}\n",
        "  szns = df.groupby('gvkey')[cols_to_deszn].transform(\n",
        "    lambda x: STL(\n",
        "        x,\n",
        "        period = 4,\n",
        "        seasonal = 9,\n",
        "        robust = True\n",
        "    ).fit().seasonal,\n",
        "  )\n",
        "  szns = szns.rename(columns=szn_cols)\n",
        "  df = pd.concat([df, szns], axis=1)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[34842, 'evq'] = df.loc[34841, 'evq']\n",
        "df.loc[34842, 'is_nan:evq'] = 1"
      ],
      "metadata": {
        "id": "Ivjw251usvo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5EJy73GnzqN"
      },
      "outputs": [],
      "source": [
        "df = deszn(df, cols_to_deszn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjJjeDCVsQJ1"
      },
      "source": [
        "We now massage our data into the pytorch forecasting dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/ECMA 31330 Project/ecma_33130_data.csv')"
      ],
      "metadata": {
        "id": "GrfrkYukHaPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ECMA 31330 Project/ecma_33130_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWdJl_J0zARw",
        "outputId": "04c46821-bff3-4021-86fa-96aee1da9868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fd2847779208>:1: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ECMA 31330 Project/ecma_33130_data.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(labels='Unnamed: 0', axis=1)"
      ],
      "metadata": {
        "id": "f9DXx5kbzXJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av1EodSOHWdA"
      },
      "outputs": [],
      "source": [
        "df['val_trap'] = df.groupby('gvkey')['ret_12m'].rank(pct=True) <= 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG4nE1PIr78k"
      },
      "outputs": [],
      "source": [
        "# these can't be categorized, since they will not appear in the training\n",
        "# and are reflected in the time\n",
        "variables_to_drop = [\n",
        "    'fyearq', 'datacqtr', 'datafqtr'\n",
        "]\n",
        "static_categoricals = [\n",
        "  'indfmt', 'consol', 'popsrc', 'datafmt', 'curcdq', 'costat', 'loc',\n",
        "]\n",
        "time_varying_known_categoricals=[\n",
        "  'gvkey', 'fqtr'\n",
        "]\n",
        "time_varying_known_reals=[\n",
        "  'ipodate'\n",
        "]\n",
        "time_varying_unknown_categoricals=[\n",
        "    col for col in df.columns\n",
        "    if col[:6] == 'is_nan'\n",
        "] + ['val_trap']\n",
        "time_varying_unknown_reals=[\n",
        "  col for col in df.columns\n",
        "  if col[:3] == 'szn'\n",
        "] + [\n",
        "  col for col in df.columns\n",
        "  if col[:3] == 'rel'\n",
        "] + [\n",
        "  col for col in df.columns\n",
        "  if col[:3] == 'ret'\n",
        "] + [\n",
        "  'eyq', 'evq', 'bkmktq', 'prclq', 'prccq', 'cdvcy', 'capxy', 'seqq',\n",
        "  'saleq', 'rectq', 'pstkq', 'ppentq', 'oiadpq', 'niq', 'ltq', 'lctq',\n",
        "  'intanq', 'dlttq', 'dlcq', 'cogsq', 'cshoq', 'cheq', 'atq', 'apq', 'actq'\n",
        "]\n",
        "# variable_groups = {\n",
        "#     'is_nan': [col for col in df.columns if col[:6] == 'is_nan'],\n",
        "# }\n",
        "#need to categorify categorical variables\n",
        "for col in static_categoricals:\n",
        "  df[col] = df[col].astype('str')\n",
        "for col in time_varying_known_categoricals:\n",
        "  df[col] = df[col].astype('str')\n",
        "for col in time_varying_unknown_categoricals:\n",
        "  df[col] = df[col].astype('str')\n",
        "df['ipodate'] = pd.factorize(df['ipodate'])[0]\n",
        "df = df.drop(labels=variables_to_drop, axis = 1)\n",
        "df['time'] = pd.factorize(df['datadate'])[0]\n",
        "train_df = df[pd.to_datetime(df['datadate']) <= pd.Timestamp(2009, 12, 31)].drop(labels='datadate', axis=1)\n",
        "test_df = df[pd.to_datetime(df['datadate']) >= pd.Timestamp(2010, 1, 1)].drop(labels='datadate', axis=1)\n",
        "df = df.drop(labels='datadate', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnyeH2j2snel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1056dd-0752-42ca-a77b-10a559922042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/197.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.7/197.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pytorch-forecasting\n",
        "from pytorch_forecasting import TimeSeriesDataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpxd3Lt3soY1",
        "outputId": "e2b3232d-3070-4d52-faa0-27b1f1d73694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py:1831: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 3937 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__gvkey': '1000'}, {'__group_id__gvkey': '10001'}, {'__group_id__gvkey': '10012'}, {'__group_id__gvkey': '10014'}, {'__group_id__gvkey': '10017'}, {'__group_id__gvkey': '10036'}, {'__group_id__gvkey': '10039'}, {'__group_id__gvkey': '10066'}, {'__group_id__gvkey': '10075'}, {'__group_id__gvkey': '10076'}]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "data = TimeSeriesDataSet(\n",
        "    df,\n",
        "    time_idx='time',\n",
        "    target='val_trap',\n",
        "    group_ids=['gvkey'],\n",
        "    max_encoder_length=20,\n",
        "    min_encoder_length=20,\n",
        "    max_prediction_length=20,\n",
        "    static_categoricals = static_categoricals,\n",
        "    time_varying_known_categoricals=time_varying_known_categoricals,\n",
        "    time_varying_known_reals=time_varying_known_reals,\n",
        "    time_varying_unknown_categoricals=time_varying_unknown_categoricals,\n",
        "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
        "    add_relative_time_idx=True,\n",
        "    allow_missing_timesteps=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = TimeSeriesDataSet.from_dataset(\n",
        "    train,\n",
        "    test_df,\n",
        "    predict=True,\n",
        "    stop_randomization=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCMHhcPu0DRG",
        "outputId": "c7f3f6f5-4c59-47a7-e7ea-5cdc2151dca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Unknown category '105394' encountered. Set `add_nan=True` to allow unknown categories\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y, return_norm, target_scale, ignore_na)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/encoders.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '105394'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5dad59b6abe3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test = TimeSeriesDataSet.from_dataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstop_randomization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mfrom_dataset\u001b[0;34m(cls, dataset, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0mnew\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \"\"\"\n\u001b[0;32m-> 1647\u001b[0;31m         return cls.from_parameters(\n\u001b[0m\u001b[1;32m   1648\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mfrom_parameters\u001b[0;34m(cls, parameters, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;31m# preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Target normalizer is separate and not in scalers.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;31m# targets and its lagged versions are handled separetely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlagged_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m                 data[name] = self.transform_values(\n\u001b[0m\u001b[1;32m   1140\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mtransform_values\u001b[0;34m(self, name, values, data, inverse, group_id, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;31m# remaining categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_categoricals\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# reals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y, return_norm, target_scale, ignore_na)\u001b[0m\n\u001b[1;32m    416\u001b[0m                     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     raise KeyError(\n\u001b[0m\u001b[1;32m    419\u001b[0m                         \u001b[0;34mf\"Unknown category '{e.args[0]}' encountered. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                         \u001b[0;34m\"Set `add_nan=True` to allow unknown categories\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Unknown category '105394' encountered. Set `add_nan=True` to allow unknown categories\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfWpd5uvswdl"
      },
      "outputs": [],
      "source": [
        "# save datasets\n",
        "train.save('/content/drive/MyDrive/Colab Notebooks/ECMA 31330 Project/train.pt')\n",
        "test.save('/content/drive/MyDrive/Colab Notebooks/ECMA 31330 Project/test.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}