{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewlys/ECMA-31330/blob/main/Project/Code/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve_8dZ_uuKvM",
        "outputId": "bdaf1606-96f6-4916-ac6d-57b21c7ad641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting statsmodels\n",
            "  Using cached statsmodels-0.14.4-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
            "Collecting numpy<3,>=1.22.3 (from statsmodels)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Collecting scipy!=1.9.2,>=1.8 (from statsmodels)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Collecting pandas!=2.1.0,>=1.4 (from statsmodels)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
            "Collecting patsy>=0.5.6 (from statsmodels)\n",
            "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\matth\\onedrive\\documents\\school\\senior year\\winter quarter\\ecma 31330\\.venv\\lib\\site-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\matth\\onedrive\\documents\\school\\senior year\\winter quarter\\ecma 31330\\.venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas!=2.1.0,>=1.4->statsmodels)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas!=2.1.0,>=1.4->statsmodels)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\matth\\onedrive\\documents\\school\\senior year\\winter quarter\\ecma 31330\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
            "Using cached statsmodels-0.14.4-cp311-cp311-win_amd64.whl (9.9 MB)\n",
            "Downloading numpy-2.2.4-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 1.3/12.9 MB 6.1 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 2.9/12.9 MB 6.7 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 3.7/12.9 MB 6.1 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 4.7/12.9 MB 5.5 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 6.0/12.9 MB 5.8 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 7.3/12.9 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 9.2/12.9 MB 6.1 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.7/12.9 MB 6.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.3/12.9 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.9/12.9 MB 6.3 MB/s eta 0:00:00\n",
            "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
            "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "Downloading scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
            "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 1.3/41.2 MB 5.6 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 2.6/41.2 MB 6.3 MB/s eta 0:00:07\n",
            "   ---- ----------------------------------- 4.2/41.2 MB 6.6 MB/s eta 0:00:06\n",
            "   ----- ---------------------------------- 5.5/41.2 MB 6.3 MB/s eta 0:00:06\n",
            "   ------ --------------------------------- 7.1/41.2 MB 6.5 MB/s eta 0:00:06\n",
            "   -------- ------------------------------- 8.4/41.2 MB 6.6 MB/s eta 0:00:05\n",
            "   --------- ------------------------------ 9.4/41.2 MB 6.6 MB/s eta 0:00:05\n",
            "   ---------- ----------------------------- 10.7/41.2 MB 6.3 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 12.1/41.2 MB 6.2 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 13.4/41.2 MB 6.2 MB/s eta 0:00:05\n",
            "   -------------- ------------------------- 14.9/41.2 MB 6.3 MB/s eta 0:00:05\n",
            "   --------------- ------------------------ 16.3/41.2 MB 6.3 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 17.8/41.2 MB 6.3 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 18.9/41.2 MB 6.3 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 20.2/41.2 MB 6.3 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 21.5/41.2 MB 6.3 MB/s eta 0:00:04\n",
            "   ---------------------- ----------------- 23.1/41.2 MB 6.3 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 24.4/41.2 MB 6.4 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 25.7/41.2 MB 6.3 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 26.7/41.2 MB 6.2 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 27.8/41.2 MB 6.2 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 28.3/41.2 MB 6.2 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 29.6/41.2 MB 6.0 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 30.9/41.2 MB 6.0 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 32.2/41.2 MB 6.0 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 33.3/41.2 MB 6.0 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 34.3/41.2 MB 6.0 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 35.4/41.2 MB 6.0 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 36.4/41.2 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 37.7/41.2 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 38.8/41.2 MB 5.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 40.1/41.2 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.2 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 41.2/41.2 MB 5.7 MB/s eta 0:00:00\n",
            "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, numpy, scipy, patsy, pandas, statsmodels\n",
            "Successfully installed numpy-2.2.4 pandas-2.2.3 patsy-1.0.1 pytz-2025.1 scipy-1.15.2 statsmodels-0.14.4 tzdata-2025.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -q statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFqz0B0VHxGV",
        "outputId": "78021bc7-3034-44cc-988f-66d614e8c475"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "data_cwd = './'\n",
        "if IN_COLAB:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    data_cwd = '/content/drive/My Drive/Colab Notebooks/ECMA 31330 Project/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzzZTUPfUD1f"
      },
      "source": [
        "We filter for companies that have been public for at least 60 months."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxSzUKKdWgHF"
      },
      "source": [
        "We begin our pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB7GU6oZbsRo"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv(data_cwd + 'ecma_33130_raw.csv')\n",
        "raw_data.datadate = pd.to_datetime(raw_data.datadate)\n",
        "raw_data.ipodate = pd.to_datetime(raw_data.ipodate)\n",
        "last_date = raw_data.groupby('gvkey').last()['datadate']\n",
        "first_date = raw_data.groupby('gvkey').first()['ipodate']\n",
        "first_date.where(pd.notnull,\n",
        "                 raw_data.groupby('gvkey').first()['datadate'],\n",
        "                 inplace=True)\n",
        "comp_to_keep = first_date + pd.DateOffset(months = 60) < last_date\n",
        "df = raw_data[raw_data['gvkey'].isin(comp_to_keep[comp_to_keep].index)]\n",
        "df = df.reset_index(drop=True)\n",
        "# Momentum Features\n",
        "df = df.sort_values(['gvkey', 'datadate'])\n",
        "# trailing returns\n",
        "for n in [3, 9, 12, 18]:\n",
        "    df[f'ret_{n}m'] = df.groupby('gvkey')['prccq'].pct_change(n, fill_method=None)\n",
        "    df[f'rel:ret_{n}m'] = df.groupby('gvkey')[f'ret_{n}m'].rank(pct=True)\n",
        "# book to market =  shareholder equity / (price close * common shares outstanding)\n",
        "df['bkmktq'] = df['seqq'] / (df['prccq'] * df['cshoq'])\n",
        "df['rel:bkmktq'] = df.groupby('datadate')['bkmktq'].rank(pct=True)\n",
        "# Enterprise Value\n",
        "df['evq'] = (\n",
        "    df['prccq'] * df['cshoq']  # Market capitalization\n",
        "    + df['dlttq']              # Long-term debt\n",
        "    + df['dlcq']               # Debt in current liabilities\n",
        "    - df['cheq']               # Cash and short-term investments\n",
        ")\n",
        "# Earnings yield\n",
        "df['eyq'] = df['oiadpq'] / df['evq']\n",
        "df['rel:eyq'] = df.groupby('datadate')['eyq'].rank(pct=True)\n",
        "# NaN Policy\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "nan_cols = [\n",
        "    f'is_nan:{col}' for col in df.columns\n",
        "    if col not in ['gvkey', 'datadate']\n",
        "]\n",
        "cols_to_nan = [col for col in df.columns if col not in ['gvkey', 'datadate']]\n",
        "nan_df = df[cols_to_nan].isna().astype(int)\n",
        "nan_df.columns = nan_cols\n",
        "df = pd.concat([df, nan_df], axis=1)\n",
        "df[cols_to_nan] = df.groupby(['gvkey', 'datadate'])[cols_to_nan].ffill()\n",
        "df[cols_to_nan] = df[cols_to_nan].fillna(0)\n",
        "# transform\n",
        "numrcl_cols = [\n",
        "    col for col in df.columns\n",
        "    if col not in ['gvkey', 'datadate', 'fyearq', 'fqtr', 'exchg', 'ipodate']\n",
        "    and col[:3] != 'rel'\n",
        "    and col[:6] != 'is_nan'\n",
        "    and pd.api.types.is_numeric_dtype(df[col])\n",
        "]\n",
        "min_val = df[numrcl_cols].min(axis=None)\n",
        "df[numrcl_cols] += np.abs(min_val)\n",
        "import numba\n",
        "norm_factor = (\n",
        "    df.groupby(['gvkey', 'datadate'])[numrcl_cols]\n",
        "      .expanding(min_periods= 1, method = 'table')\n",
        "      .mean(numeric_only = True, engine = 'numba', engine_kwargs={'parallel':True})\n",
        "      .reset_index(drop = True)\n",
        ")\n",
        "df[numrcl_cols] /= norm_factor[numrcl_cols]\n",
        "df[numrcl_cols] = np.log1p(df[numrcl_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKDVu9ellZsf"
      },
      "outputs": [],
      "source": [
        "# deseasonalization and detrend\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "cols_to_deszn = [\n",
        "    col for col in df.columns\n",
        "    if (\n",
        "        col not in ['gvkey', 'datadate', 'fyearq', 'fqtr', 'exchg', 'ipodate']\n",
        "        and col[:6] != 'is_nan'\n",
        "        and df[col].dtype in [np.float64, np.int64]\n",
        "        and df[col].nunique() > 4\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBES2oI4nnw9"
      },
      "outputs": [],
      "source": [
        "def deszn(df, cols_to_deszn):\n",
        "  szn_cols = {col:f'szn:{col}' for col in cols_to_deszn}\n",
        "  szns = df.groupby('gvkey')[cols_to_deszn].transform(\n",
        "    lambda x: STL(\n",
        "        x,\n",
        "        period = 4,\n",
        "        seasonal = 9,\n",
        "        robust = True\n",
        "    ).fit().seasonal,\n",
        "  )\n",
        "  szns = szns.rename(columns=szn_cols)\n",
        "  df = pd.concat([df, szns], axis=1)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivjw251usvo7"
      },
      "outputs": [],
      "source": [
        "df.loc[34842, 'evq'] = df.loc[34841, 'evq']\n",
        "df.loc[34842, 'is_nan:evq'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5EJy73GnzqN"
      },
      "outputs": [],
      "source": [
        "df = deszn(df, cols_to_deszn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjJjeDCVsQJ1"
      },
      "source": [
        "We now massage our data into the pytorch forecasting dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrfrkYukHaPc"
      },
      "outputs": [],
      "source": [
        "df.to_csv(data_cwd + 'ecma_33130_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWdJl_J0zARw",
        "outputId": "04c46821-bff3-4021-86fa-96aee1da9868"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_12948\\3271627276.py:1: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(data_cwd + 'ecma_33130_data.csv')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(data_cwd + 'ecma_33130_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f9DXx5kbzXJD"
      },
      "outputs": [],
      "source": [
        "df = df.drop(labels='Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Av1EodSOHWdA"
      },
      "outputs": [],
      "source": [
        "df['val_trap'] = df.groupby('gvkey')['ret_12m'].rank(pct=True) <= 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vG4nE1PIr78k"
      },
      "outputs": [],
      "source": [
        "# these can't be categorized, since they will not appear in the training\n",
        "# and are reflected in the time\n",
        "variables_to_drop = [\n",
        "    'fyearq', 'datacqtr', 'datafqtr'\n",
        "]\n",
        "static_categoricals = [\n",
        "  'indfmt', 'consol', 'popsrc', 'datafmt', 'curcdq', 'costat', 'loc',\n",
        "]\n",
        "time_varying_known_categoricals=[\n",
        "  'gvkey', 'fqtr'\n",
        "]\n",
        "time_varying_known_reals=[\n",
        "  'ipodate'\n",
        "]\n",
        "time_varying_unknown_categoricals=[\n",
        "    col for col in df.columns\n",
        "    if col[:6] == 'is_nan'\n",
        "] + ['val_trap']\n",
        "time_varying_unknown_reals=[\n",
        "  col for col in df.columns\n",
        "  if col[:3] == 'szn'\n",
        "] + [\n",
        "  col for col in df.columns\n",
        "  if col[:3] == 'rel'\n",
        "] + [\n",
        "  col for col in df.columns\n",
        "  if col[:3] == 'ret'\n",
        "] + [\n",
        "  'eyq', 'evq', 'bkmktq', 'prclq', 'prccq', 'cdvcy', 'capxy', 'seqq',\n",
        "  'saleq', 'rectq', 'pstkq', 'ppentq', 'oiadpq', 'niq', 'ltq', 'lctq',\n",
        "  'intanq', 'dlttq', 'dlcq', 'cogsq', 'cshoq', 'cheq', 'atq', 'apq', 'actq'\n",
        "]\n",
        "# variable_groups = {\n",
        "#     'is_nan': [col for col in df.columns if col[:6] == 'is_nan'],\n",
        "# }\n",
        "#need to categorify categorical variables\n",
        "for col in static_categoricals:\n",
        "  df[col] = df[col].astype('str')\n",
        "for col in time_varying_known_categoricals:\n",
        "  df[col] = df[col].astype('str')\n",
        "for col in time_varying_unknown_categoricals:\n",
        "  df[col] = df[col].astype('str')\n",
        "df['ipodate'] = pd.factorize(df['ipodate'])[0]\n",
        "df = df.drop(labels=variables_to_drop, axis = 1)\n",
        "df['time'] = pd.factorize(df['datadate'])[0]\n",
        "train_df = df[pd.to_datetime(df['datadate']) <= pd.Timestamp(2002, 1, 1)].drop(columns='datadate')\n",
        "test_df = df[pd.Timestamp(2010, 1, 1) <= pd.to_datetime(df['datadate'])].drop(columns='datadate')\n",
        "val_df = df[pd.to_datetime(df['datadate']) <= pd.Timestamp(2009, 12, 31)].drop(columns = 'datadate')\n",
        "df = df.drop(labels='datadate', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnyeH2j2snel",
        "outputId": "8b1056dd-0752-42ca-a77b-10a559922042"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\matth\\OneDrive\\Documents\\School\\Senior Year\\Winter Quarter\\ECMA 31330\\.venv\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pytorch-forecasting\n",
        "from pytorch_forecasting import TimeSeriesDataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpxd3Lt3soY1",
        "outputId": "e2b3232d-3070-4d52-faa0-27b1f1d73694"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\matth\\OneDrive\\Documents\\School\\Senior Year\\Winter Quarter\\ECMA 31330\\.venv\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1831: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 3937 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__gvkey': '1000'}, {'__group_id__gvkey': '10001'}, {'__group_id__gvkey': '10012'}, {'__group_id__gvkey': '10014'}, {'__group_id__gvkey': '10017'}, {'__group_id__gvkey': '10036'}, {'__group_id__gvkey': '10039'}, {'__group_id__gvkey': '10066'}, {'__group_id__gvkey': '10075'}, {'__group_id__gvkey': '10076'}]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "data = TimeSeriesDataSet(\n",
        "    df,\n",
        "    time_idx='time',\n",
        "    target='val_trap',\n",
        "    group_ids=['gvkey'],\n",
        "    max_encoder_length=20,\n",
        "    min_encoder_length=20,\n",
        "    max_prediction_length=20,\n",
        "    static_categoricals = static_categoricals,\n",
        "    time_varying_known_categoricals=time_varying_known_categoricals,\n",
        "    time_varying_known_reals=time_varying_known_reals,\n",
        "    time_varying_unknown_categoricals=time_varying_unknown_categoricals,\n",
        "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
        "    add_relative_time_idx=True,\n",
        "    allow_missing_timesteps=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCMHhcPu0DRG",
        "outputId": "c7f3f6f5-4c59-47a7-e7ea-5cdc2151dca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\matth\\OneDrive\\Documents\\School\\Senior Year\\Winter Quarter\\ECMA 31330\\.venv\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1831: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 5496 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__gvkey': '1000'}, {'__group_id__gvkey': '10001'}, {'__group_id__gvkey': '10012'}, {'__group_id__gvkey': '10014'}, {'__group_id__gvkey': '10017'}, {'__group_id__gvkey': '10036'}, {'__group_id__gvkey': '10039'}, {'__group_id__gvkey': '100644'}, {'__group_id__gvkey': '10066'}, {'__group_id__gvkey': '10075'}]\n",
            "  warnings.warn(\n",
            "c:\\Users\\matth\\OneDrive\\Documents\\School\\Senior Year\\Winter Quarter\\ECMA 31330\\.venv\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1831: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 8260 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__gvkey': '1000'}, {'__group_id__gvkey': '10000'}, {'__group_id__gvkey': '10001'}, {'__group_id__gvkey': '10002'}, {'__group_id__gvkey': '10004'}, {'__group_id__gvkey': '10006'}, {'__group_id__gvkey': '10008'}, {'__group_id__gvkey': '10010'}, {'__group_id__gvkey': '10012'}, {'__group_id__gvkey': '10014'}]\n",
            "  warnings.warn(\n",
            "c:\\Users\\matth\\OneDrive\\Documents\\School\\Senior Year\\Winter Quarter\\ECMA 31330\\.venv\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1831: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 2544 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__gvkey': '10002'}, {'__group_id__gvkey': '10063'}, {'__group_id__gvkey': '1013'}, {'__group_id__gvkey': '10156'}, {'__group_id__gvkey': '10187'}, {'__group_id__gvkey': '10190'}, {'__group_id__gvkey': '10200'}, {'__group_id__gvkey': '10213'}, {'__group_id__gvkey': '10277'}, {'__group_id__gvkey': '10286'}]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train = TimeSeriesDataSet.from_dataset(\n",
        "    data,\n",
        "    train_df\n",
        ")\n",
        "val = TimeSeriesDataSet.from_dataset(\n",
        "    data,\n",
        "    val_df,\n",
        "    predict=True,\n",
        "    stop_randomization=True\n",
        ")\n",
        "test = TimeSeriesDataSet.from_dataset(\n",
        "    data,\n",
        "    test_df,\n",
        "    predict=True,\n",
        "    stop_randomization=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mfWpd5uvswdl"
      },
      "outputs": [],
      "source": [
        "# save datasets\n",
        "train.save(data_cwd + 'train.pt')\n",
        "test.save(data_cwd + 'test.pt')\n",
        "val.save(data_cwd + 'val.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
